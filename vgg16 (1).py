# -*- coding: utf-8 -*-
"""vgg16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iZmzb7cVYHmGLcUMqpHQynCdNf_EO0u7
"""

import os
import seaborn as sns
import pandas as pd
import numpy as np
import cv2 as cv
from tqdm import tqdm
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras import layers
from tensorflow.keras import Sequential
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img,img_to_array
from tensorflow.keras.layers import Flatten,Dense,Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.utils import to_categorical

from google.colab import drive
drive.mount('/content/gdrive')

dataset = pd.read_csv("/content/gdrive/MyDrive/full_df.csv")

dataset

def process_dataset(data):

    data["left_cataract"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("cataract",x))
    data["right_cataract"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("cataract",x))

    data["LD"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("non proliferative retinopathy",x))
    data["RD"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("non proliferative retinopathy",x))

    data["LG"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("glaucoma",x))
    data["RG"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("glaucoma",x))

    data["LH"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("hypertensive",x))
    data["RH"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("hypertensive",x))

    data["LM"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("myopia",x))
    data["RM"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("myopia",x))

    data["LA"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("macular degeneration",x))
    data["RA"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("macular degeneration",x))

    data["LO"] = data["Left-Diagnostic Keywords"].apply(lambda x: has_condn("drusen",x))
    data["RO"] = data["Right-Diagnostic Keywords"].apply(lambda x: has_condn("drusen",x))

    left_cataract_images = data.loc[(data.C ==1) & (data.left_cataract == 1)]["Left-Fundus"].values
    right_cataract_images = data.loc[(data.C == 1) & (data.right_cataract == 1)]["Right-Fundus"].values

    left_normal = data.loc[(data.C == 0) & (data["Left-Diagnostic Keywords"] == "normal fundus")]['Left-Fundus'].sample(350,random_state=42).values
    right_normal = data.loc[(data.C == 0) & (data["Right-Diagnostic Keywords"] == "normal fundus")]['Right-Fundus'].sample(350,random_state=42).values

    left_diab = data.loc[(data.C == 0) & (data.LD == 1)]["Left-Fundus"].values
    right_diab = data.loc[(data.C == 0) & (data.RD == 1)]["Right-Fundus"].values

    left_glaucoma = data.loc[(data.C == 0) & (data.LG == 1)]["Left-Fundus"].values
    right_glaucoma = data.loc[(data.C == 0) & (data.RG == 1)]["Right-Fundus"].values

    left_hyper = data.loc[(data.C == 0) & (data.LH == 1)]["Left-Fundus"].values
    right_hyper = data.loc[(data.C == 0) & (data.RH == 1)]["Right-Fundus"].values

    left_myopia = data.loc[(data.C == 0) & (data.LM == 1)]["Left-Fundus"].values
    right_myopia = data.loc[(data.C == 0) & (data.RM == 1)]["Right-Fundus"].values

    left_age = data.loc[(data.C == 0) & (data.LA == 1)]["Left-Fundus"].values
    right_age = data.loc[(data.C == 0) & (data.RA == 1)]["Right-Fundus"].values

    left_other = data.loc[(data.C == 0) & (data.LO == 1)]["Left-Fundus"].values
    right_other = data.loc[(data.C == 0) & (data.RO == 1)]["Right-Fundus"].values

    normalones = np.concatenate((left_normal,right_normal),axis = 0);
    cataractones = np.concatenate((left_cataract_images,right_cataract_images),axis = 0);
    diabones = np.concatenate((left_diab,right_diab),axis = 0);
    glaucoma = np.concatenate((left_glaucoma,right_glaucoma),axis = 0);
    hyper = np.concatenate((left_hyper,right_hyper),axis = 0);
    myopia = np.concatenate((left_myopia,right_myopia),axis = 0);
    age = np.concatenate((left_age,right_age),axis=0);
    other = np.concatenate((left_other,right_other),axis = 0);

    return normalones,cataractones,diabones,glaucoma,hyper,myopia,age,other;

def has_condn(term, text):
    if term in text:
        return 1
    else:
        return 0

normal , cataract , diab, glaucoma , hyper , myopia , age, other = process_dataset(dataset);

print("Dataset stats::")
print("Normal ::" , len(normal))
print("Cataract ::" , len(cataract))
print("Diabetes ::" , len(diab))
print("Glaucoma ::" , len(glaucoma))
print("Hypertension ::" , len(hyper))
print("Myopia ::" , len(myopia))
print("Age Issues ::" , len(age))
print("Other ::" , len(other))

from sklearn.preprocessing import LabelEncoder

label_encoders = {}
for column in dataset.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    dataset[column] = le.fit_transform(dataset[column])
    label_encoders[column] = le

print(dataset.corr())

plt.figure(figsize = (15,8))
sns.heatmap(dataset.corr(), annot=True, linewidth=2, linecolor = 'lightgray')
plt.show()

from tensorflow.keras.preprocessing.image import load_img,img_to_array
from tqdm import tqdm
import cv2
import random

dataset_dir = "/content/gdrive/MyDrive/preprocessed_images_1/"
image_size=224
labels = []
dataset = []
def data_gen(imagecategory , label):
    for img in tqdm(imagecategory):
        imgpath = os.path.join(dataset_dir,img);

        try:
            image = cv2.imread(imgpath,cv2.IMREAD_COLOR)
            image = cv2.resize(image,(image_size,image_size))
        except:
            continue;
        dataset.append([np.array(image),np.array(label)]);
    random.shuffle(dataset);

    return dataset;

dataset = data_gen(normal,0)
dataset = data_gen(cataract,1)
dataset = data_gen(diab,2)
dataset = data_gen(glaucoma,3)
dataset = data_gen(hyper,4)
dataset = data_gen(myopia,5)
dataset = data_gen(age,6)
dataset = data_gen(other,7)

len(dataset)

plt.figure(figsize=(12,7))
for i in range(10):
    sample = random.choice(range(len(dataset)))
    image = dataset[sample][0]
    category = dataset[sample][1]

    if category== 0:
        label = "Normal"
    elif category == 1 :
        label = "Cataract"
    elif category == 2:
        label = "Diabetes"
    elif category == 3:
        label = "Glaucoma"
    elif category == 4:
        label = "Hypertension"
    elif category == 5:
        label = "Myopia"
    elif category == 6:
        label = "Age Issues"
    else:
        label = "Other"

    plt.subplot(2,6,i+1)
    plt.imshow(image)
    plt.xlabel(label)
plt.tight_layout()

from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

train_x = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3);
train_y = np.array([i[1] for i in dataset])

x_train, x_temp, y_train, y_temp = train_test_split(train_x, train_y, test_size=0.2, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)


y_train_cat = to_categorical(y_train, num_classes=8)
y_val_cat = to_categorical(y_val, num_classes=8)
y_test_cat = to_categorical(y_test, num_classes=8)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

idg = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,

    horizontal_flip=True,
    vertical_flip=False,
    fill_mode='nearest'
)

idg_test = ImageDataGenerator(rescale=1./255)

idg.fit(x_train)
idg.fit(x_val)
idg_test.fit(x_test)

import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16

input_shape = (224, 224, 3)
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)

vgg16.summary()

for layer in vgg16.layers:
    layer.trainable = False

input_shape = (224, 224, 3)
vgg16 = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)

flat = layers.Flatten()(vgg16.output)
dense1 = layers.Dense(2048, activation="relu")(flat)
dropout1 = layers.Dropout(0.4)(dense1)
dense2 = layers.Dense(2048, activation="relu")(dropout1)
dropout2 = layers.Dropout(0.4)(dense2)
output = layers.Dense(8, activation="softmax")(dropout2)

final_vgg16 = tf.keras.models.Model(inputs=[vgg16.input], outputs=[output])

final_vgg16.summary()

count = 0
for layer in final_vgg16.layers:
  count = count +1
print(count)

tf.keras.utils.plot_model(final_vgg16, show_shapes = True, show_layer_names=True)

from tensorflow.keras.optimizers import Adam
final_vgg16.compile(optimizer=Adam(learning_rate=1e-4),
                    loss='categorical_crossentropy',
                    metrics=['accuracy'])

train_data = (x_train, y_train_cat)
validation_data = (x_val, y_val_cat)
test_data = (x_test, y_test_cat)

history = final_vgg16.fit(train_data[0], train_data[1], validation_data=(validation_data[0], validation_data[1]), batch_size=32, epochs=50)

train_loss, train_accuracy = final_vgg16.evaluate(train_data[0], train_data[1], verbose=0)
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")

val_loss, val_accuracy = final_vgg16.evaluate(validation_data[0], validation_data[1], verbose=0)
print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")

test_loss, test_accuracy = final_vgg16.evaluate(test_data[0], test_data[1], verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
y_pred = []
for i in final_vgg16.predict(x_test):
    y_pred.append(np.argmax(np.array(i)).astype("int32"))

print(y_pred)

plt.figure(figsize=(12,7))
for i in range(20):
    sample = random.choice(range(len(x_test)))
    image = x_test[sample]
    category = y_test[sample]
    pred_category = y_pred[sample]

    if category== 0:
        label = "Normal"
    elif category == 1 :
        label = "Cataract"
    elif category == 2:
        label = "Diabetes"
    elif category == 3:
        label = "Glaucoma"
    elif category == 4:
        label = "Hypertension"
    elif category == 5:
        label = "Myopia"
    elif category == 6:
        label = "Age Issues"
    else:
        label = "Other"

    if pred_category== 0:
        pred_label = "Normal"
    elif pred_category == 1 :
        pred_label = "Cataract"
    elif pred_category == 2:
        pred_label = "Diabetes"
    elif pred_category == 3:
        pred_label = "Glaucoma"
    elif pred_category == 4:
        pred_label = "Hypertension"
    elif pred_category == 5:
        pred_label = "Myopia"
    elif pred_category == 6:
        pred_label = "Age Issues"
    else:
        pred_label = "Other"

    plt.subplot(4,5,i+1)
    plt.imshow(image)
    plt.xlabel("Actual:{}\nPrediction:{}".format(label,pred_label))
plt.tight_layout()

final_vgg16.save("ODIR_VGG16.h5")

final_vgg16.save('ODIR_VGG16.keras')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()


plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score

class_names = ['Normal', 'Cataract', 'Diabetes', 'Glaucoma', 'Hypertension', 'Myopia', 'Age Issues', 'Other']
y_pred = final_vgg16.predict(x_test)

y_pred_classes = np.argmax(y_pred, axis=1)

y_true_classes = np.argmax(y_test_cat, axis=1)

report = classification_report(y_true_classes, y_pred_classes)
print(report)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.models import load_model

class_names = [
    "Normal", "Cataract", "Diabetes", "Glaucoma",
    "Hypertension", "Myopia", "Age Issues", "Other"
]

y_true = np.argmax(y_test_cat, axis=1)
y_pred_classes = np.argmax(y_pred, axis=1)

conf_matrix = confusion_matrix(y_true, y_pred_classes)

# Display the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# Print classification report
report = classification_report(y_true, y_pred_classes, target_names=class_names)
print("Classification Report:\n", report)

!pip install lime

from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt

explainer = lime_image.LimeImageExplainer()

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

def preprocess_image(img, target_size=(224, 224)):
    img = np.expand_dims(img, axis=0)
    img = img / 255.0  # Normalize if your model expects it
    return img

# Set the path to your dataset
dataset_path = '/content/gdrive/MyDrive/preprocessed_images_1/'

# Example: Set the path to an image for testing
image_path = dataset_path + '0_right.jpg'  # Adjust to match your file structure

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

import numpy as np
from PIL import Image

dataset_path = '/content/drive/MyDrive/preprocessed_images_1/'

image_path = dataset_path + '0_right.jpg'  # Adjust to match your file structure

# Load the image
test_image_array = np.array(Image.open(image_path))

# Preprocess the test image
input_img = preprocess_image(test_image_array)

# ... (rest of your existing code) ...

import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries
import shap
from PIL import Image
from skimage.color import label2rgb






def lime_explanation(model, image, class_names):
    explainer = lime_image.LimeImageExplainer()

    # Generate explanation
    explanation = explainer.explain_instance(
        image.astype('double'),
        model.predict,
        top_labels=1,
        hide_color=0,
        num_samples=1000
    )

    # Get the mask and display explanation
    pred_class = np.argmax(model.predict(image[np.newaxis, ...]))
    temp, mask = explanation.get_image_and_mask(
        label=pred_class,
        positive_only=True,
        hide_rest=False,
        num_features=5,
        min_weight=0.0
    )

    plt.imshow(mark_boundaries(image, mask))
    plt.title(f'LIME Explanation for Class: {class_names[pred_class]}')
    plt.axis('off')
    plt.show()


def shap_explanation(model, images):
    explainer = shap.GradientExplainer(model, images[:10])  # Use a subset of background images

    # Compute SHAP values
    shap_values = explainer.shap_values(images)

    # Visualize results
    shap.image_plot(shap_values, images)




# Load the saved model
model = keras.models.load_model('ODIR_VGG16.keras')

# Preprocess an example test image
test_image = np.array(Image.open(image_path).resize((224, 224)))
test_image_preprocessed = preprocess_image(test_image)

# Class Names
class_names = [
    "Normal", "Cataract", "Diabetes", "Glaucoma",
    "Hypertension", "Myopia", "Age Issues", "Other"
]

# LIME Explanation
lime_explanation(model, test_image, class_names)

# SHAP Explanation (pass batch of test images)
shap_explanation(model, x_test[:10])

from google.colab import files
files.download('ODIR_VGG16.keras')
files.download('ODIR_VGG16.h5')